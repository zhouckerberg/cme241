{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Gradient Theorem\n",
    "\n",
    "$$\\nabla_{\\theta}J(\\theta) = \\int_S \\rho^{\\pi}(s) \\int_A \\nabla_{\\theta}\\pi(s,a;\\theta) Q^\\pi (s,a)\\operatorname{d}\\!a\\operatorname{d}\\!s$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof\n",
    "\n",
    "$$J(\\theta) \n",
    "= \\int_S p_0(s_0) V^\\pi(s_0) \\operatorname{d}\\!s_0 \n",
    "= \\int_S p_0(s_0) \\int_{A} \\pi(s_0, a_0 ; \\theta) Q^\\pi(s_0,a_0) \\operatorname{d}\\!a_0 \\operatorname{d}\\!s_0$$\n",
    "\n",
    "Hence,\n",
    "\n",
    "$$\\nabla_{\\theta} J(\\theta) \n",
    "= \\int_S p_0(s_0) \\int_{A} \\nabla_{\\theta} \\pi(s_0, a_0 ; \\theta) Q^\\pi(s_0,a_0) \\operatorname{d}\\!a_0 \\operatorname{d}\\!s_0\n",
    "+ \\int_S p_0(s_0) \\int_{A} \\pi(s_0, a_0 ; \\theta) \\nabla_{\\theta} Q^\\pi(s_0,a_0) \\operatorname{d}\\!a_0 \\operatorname{d}\\!s_0$$\n",
    "\n",
    "The second term in the sum is equal to \n",
    "\n",
    "\\begin{align*}\n",
    "\\int_S p_0(s_0) \\int_{A} \\pi(s_0, a_0 ; \\theta) \\nabla_{\\theta} Q^\\pi(s_0,a_0) \\operatorname{d}\\!a_0 \\operatorname{d}\\!s_0\n",
    "&= \\int_S p_0(s_0) \\int_A \\pi(s_0, a_0 ; \\theta) \\nabla_{\\theta} \\left(\\int_S \\gamma \\mathcal P_{s0,s1}^{a_0}V^\\pi(s_1) \\operatorname{d}\\!s_1\\right) \\operatorname{d}\\! a_0 \\operatorname{d}\\! s_0 \\\\\n",
    "&= \\int_S \\left( \\int_S \\gamma p_0(s_0) \\int_A \\pi(s_0, a_0 ; \\theta)P_{s_0,s_1}^{a_0}   \\operatorname{d}\\! a_0 \\operatorname{d}\\! s_0 \\right) \\nabla_{\\theta}V^\\pi(s_1) \\operatorname{d}\\! s_1 \\\\\n",
    "&= \\int_S \\left( \\int_S \\gamma p_0(s_0) p(s_0 \\rightarrow s_1, 1, \\pi) \\operatorname{d}\\! s_0 \\right) \\nabla_{\\theta} \\left(\\int_A \\pi(s_1, a_1 ; \\theta) Q^\\pi(s_1, a_1) \\operatorname{d}\\! a_1 \\right) \\operatorname{d}\\! s_1 \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Iterating yields\n",
    "$$\\sum_{t=0}^\\infty \\int_S \\int_S \\gamma^t p_0(s_0) p(s_0 \\rightarrow s_t, t, \\pi) \\operatorname{d}\\! s_0 \\int_A \\nabla_\\theta \\pi(s_t, a_t; \\theta) Q^\\pi(s_t, a_t) \\operatorname{d}\\! a_t \\operatorname{d}\\! s_t$$\n",
    "\n",
    "Interverting the sum and the integral gives\n",
    "$$\\int_S \\int_S \\sum_{t=0}^\\infty \\gamma^t p_0(s_0) p(s_0 \\rightarrow s_t, t, \\pi) \\operatorname{d}\\! s_0 \\int_{A} \\nabla_{\\theta}\\pi(s,a;\\theta) Q^\\pi (s,a)\\operatorname{d}\\!a\\operatorname{d}\\!s$$\n",
    "\n",
    "i.e. \n",
    "$$\\int_S \\rho^\\pi(s) \\int_{A} \\nabla_{\\theta}\\pi(s,a;\\theta) Q^\\pi (s,a)\\operatorname{d}\\!a\\operatorname{d}\\!s$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Scores\n",
    "\n",
    "$\\forall s \\in S, a \\in A, \\, \\pi(s, a; \\theta) = \\frac{e^{\\theta^{T} \\phi(s, a)}}{\\sum_{b} e^{\\theta^{T} \\phi(s, b)}}$\n",
    "\n",
    "The score function is $$\\nabla_{\\theta} \\log \\pi(s, a; \\theta) = \\phi(s, a) - \\sum_{b} \\pi(s, b  ; \\theta) \\phi(s, b) = \\phi(s, a) - \\mathbb{E}_{\\pi}[\\phi(s, \\cdot)]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Scores\n",
    "\n",
    "The score function is $$\\nabla_{\\theta} \\log \\pi(s, a; \\theta) = \\frac{(a-\\theta^T\\phi(s))\\phi(s)}{\\sigma^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REINFORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.reinforce import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compatible Function Approximation Theorem\n",
    "\n",
    "If \n",
    "- the Critic gradient is compatible with the Actor score function \n",
    "$$\\nabla_w Q(s, a; w) = \\nabla_\\theta \\log\\pi(s, a; \\theta)$$\n",
    "- the Critic parameters $w$ minimize the following mean-squared error\n",
    "$$\\varepsilon = \\int_S \\rho^\\pi(s) \\int_A \\pi(s, a; \\theta) \\left(Q^\\pi(s,a) - Q(s,a; w)\\right)^2 \\operatorname{d}\\!a \\operatorname{d}\\! s$$\n",
    "\n",
    "Then the Policy Gradient using critic $Q(s, a; w)$ is exact\n",
    "$$\\nabla_\\theta J(\\theta) = \\int_S \\rho^\\pi(s) \\int_A \\nabla_\\theta  \\pi(s, a; \\theta) Q(s,a; w)\\operatorname{d}\\!a \\operatorname{d}\\! s$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $w$ that minimizes $\\varepsilon$, we have \n",
    "\\begin{align*}\n",
    "0 &= \\int_S \\rho^\\pi(s) \\int_A \\pi(s, a; \\theta) \\left(Q^\\pi(s,a) - Q(s,a; w)\\right) \\nabla_w Q(s,a; w) \\operatorname{d}\\!a \\operatorname{d}\\! s \\\\\n",
    "&= \\int_S \\rho^\\pi(s) \\int_A \\pi(s, a; \\theta) \\left(Q^\\pi(s,a) - Q(s,a; w)\\right) \\nabla_\\theta \\log\\pi(s, a; \\theta) \\operatorname{d}\\!a \\operatorname{d}\\! s \n",
    "\\end{align*}\n",
    "Hence, $$\\int_S \\rho^\\pi(s) \\int_A \\pi(s, a; \\theta) Q^\\pi(s,a)\\nabla_\\theta \\log\\pi(s, a; \\theta) \\operatorname{d}\\!a \\operatorname{d}\\! s = \\int_S \\rho^\\pi(s) \\int_A \\pi(s, a; \\theta) Q(s,a; w) \\nabla_\\theta \\log\\pi(s, a; \\theta) \\operatorname{d}\\!a \\operatorname{d}\\! s $$\n",
    "i.e.\n",
    "\\begin{align*}\n",
    "\\nabla_\\theta J(\\theta) &= \\int_S \\rho^\\pi(s) \\int_A \\pi(s, a; \\theta) Q(s,a; w) \\nabla_\\theta \\log\\pi(s, a; \\theta) \\operatorname{d}\\!a \\operatorname{d}\\! s\\\\\n",
    "&= \\int_S \\rho^\\pi(s) \\int_A \\nabla_\\theta  \\pi(s, a; \\theta) Q(s,a; w)\\operatorname{d}\\!a \\operatorname{d}\\! s\n",
    "\\end{align*}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
